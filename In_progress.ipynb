{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,f1_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "from joblib import dump, load\n",
    "import librosa.display  \n",
    "\n",
    "from utils import data_process, visualize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1118\n",
       "1     372\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "X =np.load('/home/yuanshao/EQ_Place/code/data/X_8_28.npy', allow_pickle=True)\n",
    "Y =np.load('/home/yuanshao/EQ_Place/code/data/Y_8_28.npy')\n",
    "\n",
    "pd.value_counts(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一长度\n",
    "\n",
    "for i in range(len(X)):\n",
    "    if X[i][0].shape[0]!=7201:\n",
    "        X[i][0]=data_process.data_resample( X[i][0], 7201)\n",
    "        X[i][1]=data_process.data_resample( X[i][1], 7201)\n",
    "        X[i][2]=data_process.data_resample( X[i][2], 7201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1490/1490 [00:30<00:00, 49.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# 特征提取\n",
    "feature = []\n",
    "for i in tqdm(range(len(X))):\n",
    "    ex, ey, ez = X[i][0], X[i][1], X[i][2]\n",
    "    iqr_x = data_process.cal_IQR(ex)\n",
    "    iqr_y = data_process.cal_IQR(ey)\n",
    "    iqr_z = data_process.cal_IQR(ez)\n",
    "    zcr_x = data_process.ZCR(ex)\n",
    "    zcr_y = data_process.ZCR(ey)\n",
    "    zcr_z = data_process.ZCR(ez)\n",
    "    cav=data_process.CAV([ex,ey,ez])\n",
    "    feature.append([iqr_x, iqr_y, iqr_z ,zcr_x, zcr_y, zcr_z, cav])\n",
    "feature=np.array(feature)\n",
    "feature=feature[:,:,np.newaxis,:]  \n",
    "# np.save('feature_8_29',feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 7, 1, 36)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.load('./feature_8_28.npy')\n",
    "# Y =np.load('/home/xxx/EQ_Place/code/data/Y_8_28.npy')\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, Y,test_size=0.2, \n",
    "                                                     random_state=1)\n",
    "\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "traindata =TensorDataset(x_train,y_train)\n",
    "testdata = TensorDataset(x_test,y_test)\n",
    "train_loader = DataLoader(traindata,batch_size = 256,shuffle=True)\n",
    "test_loader = DataLoader(testdata,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([372, 7, 1, 36])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     19
    ]
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    losst=[]\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(batch_idx+1)%30 == 0: \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))#Use torch.Tensor.item() to get a Python number from a tensor containing a single value:\n",
    "            losst.append(loss.item())\n",
    "    return losst\n",
    "            \n",
    "#测试过程\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()#找到正确的预测值\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(7, 32, (1, 3), stride=1, padding=(0, 1)), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)))\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, (1, 3), stride=1, padding=(0, 1)), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)))\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, (1, 3), stride=1, padding=(0, 1)), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)))\n",
    "\n",
    "        self.fc1 =nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256,2))\n",
    "        self.fla = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.fla(x)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(7, 32, (1, 5), stride=1, padding=(0, 1)), nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(1, 3)))\n",
    "\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(32, 64, (1, 5), stride=1, padding=(0, 1)), nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(1, 3)))\n",
    "\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 128, (1, 5), stride=1, padding=(0, 1)), nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=(1, 3)))\n",
    "\n",
    "#         self.fc1 =nn.Sequential(\n",
    "#             nn.Linear(1536, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(256,2))\n",
    "#         self.fla = nn.Flatten()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.conv3(x)\n",
    "# #         print(x.shape)\n",
    "# #         x, (h_n, c_n) = self.lstm1(x)\n",
    "#         x = self.fla(x)\n",
    "#         print(x.shape)\n",
    "#         x = self.fc1(x)\n",
    "\n",
    "#         return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.1 sec:\n",
      "\n",
      "Test set: Average loss: 0.5833, Accuracy: 227/298 (76.17%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.5554, Accuracy: 227/298 (76.17%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.5401, Accuracy: 227/298 (76.17%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.5203, Accuracy: 227/298 (76.17%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4831, Accuracy: 235/298 (78.86%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4364, Accuracy: 248/298 (83.22%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4199, Accuracy: 241/298 (80.87%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4468, Accuracy: 239/298 (80.20%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4242, Accuracy: 245/298 (82.21%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4206, Accuracy: 241/298 (80.87%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4101, Accuracy: 244/298 (81.88%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4113, Accuracy: 242/298 (81.21%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4073, Accuracy: 243/298 (81.54%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4027, Accuracy: 242/298 (81.21%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4102, Accuracy: 247/298 (82.89%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3980, Accuracy: 245/298 (82.21%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4062, Accuracy: 246/298 (82.55%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3949, Accuracy: 247/298 (82.89%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3923, Accuracy: 248/298 (83.22%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4105, Accuracy: 248/298 (83.22%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4278, Accuracy: 249/298 (83.56%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3902, Accuracy: 246/298 (82.55%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3863, Accuracy: 247/298 (82.89%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3956, Accuracy: 250/298 (83.89%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3873, Accuracy: 246/298 (82.55%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3908, Accuracy: 247/298 (82.89%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3977, Accuracy: 251/298 (84.23%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3704, Accuracy: 251/298 (84.23%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3766, Accuracy: 249/298 (83.56%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.4437, Accuracy: 246/298 (82.55%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3932, Accuracy: 250/298 (83.89%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3899, Accuracy: 253/298 (84.90%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3680, Accuracy: 253/298 (84.90%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3482, Accuracy: 256/298 (85.91%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3557, Accuracy: 253/298 (84.90%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3427, Accuracy: 259/298 (86.91%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3252, Accuracy: 257/298 (86.24%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3320, Accuracy: 260/298 (87.25%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3087, Accuracy: 258/298 (86.58%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3082, Accuracy: 260/298 (87.25%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3228, Accuracy: 266/298 (89.26%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2880, Accuracy: 262/298 (87.92%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2968, Accuracy: 266/298 (89.26%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2907, Accuracy: 269/298 (90.27%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2556, Accuracy: 267/298 (89.60%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2476, Accuracy: 267/298 (89.60%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2722, Accuracy: 271/298 (90.94%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2406, Accuracy: 268/298 (89.93%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2351, Accuracy: 269/298 (90.27%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.5273, Accuracy: 252/298 (84.56%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3120, Accuracy: 262/298 (87.92%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3362, Accuracy: 269/298 (90.27%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3556, Accuracy: 258/298 (86.58%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3300, Accuracy: 262/298 (87.92%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2897, Accuracy: 267/298 (89.60%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2687, Accuracy: 267/298 (89.60%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2534, Accuracy: 271/298 (90.94%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2207, Accuracy: 273/298 (91.61%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2223, Accuracy: 276/298 (92.62%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2114, Accuracy: 275/298 (92.28%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1982, Accuracy: 276/298 (92.62%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1969, Accuracy: 278/298 (93.29%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3741, Accuracy: 266/298 (89.26%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.7288, Accuracy: 216/298 (72.48%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3917, Accuracy: 260/298 (87.25%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2888, Accuracy: 268/298 (89.93%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3223, Accuracy: 267/298 (89.60%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.3095, Accuracy: 264/298 (88.59%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2862, Accuracy: 265/298 (88.93%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2857, Accuracy: 264/298 (88.59%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2355, Accuracy: 276/298 (92.62%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2304, Accuracy: 275/298 (92.28%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1965, Accuracy: 274/298 (91.95%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1803, Accuracy: 278/298 (93.29%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1860, Accuracy: 282/298 (94.63%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1732, Accuracy: 282/298 (94.63%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1824, Accuracy: 274/298 (91.95%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2127, Accuracy: 275/298 (92.28%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2029, Accuracy: 275/298 (92.28%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2347, Accuracy: 277/298 (92.95%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1739, Accuracy: 276/298 (92.62%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1579, Accuracy: 279/298 (93.62%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1790, Accuracy: 280/298 (93.96%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1526, Accuracy: 282/298 (94.63%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1407, Accuracy: 279/298 (93.62%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1419, Accuracy: 281/298 (94.30%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1385, Accuracy: 281/298 (94.30%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1353, Accuracy: 282/298 (94.63%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1293, Accuracy: 283/298 (94.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1637, Accuracy: 285/298 (95.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1265, Accuracy: 283/298 (94.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1264, Accuracy: 285/298 (95.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1199, Accuracy: 283/298 (94.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1234, Accuracy: 283/298 (94.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1534, Accuracy: 282/298 (94.63%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1566, Accuracy: 281/298 (94.30%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.2106, Accuracy: 286/298 (95.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1222, Accuracy: 283/298 (94.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1203, Accuracy: 283/298 (94.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1183, Accuracy: 285/298 (95.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1115, Accuracy: 284/298 (95.30%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1094, Accuracy: 286/298 (95.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1182, Accuracy: 287/298 (96.31%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1432, Accuracy: 287/298 (96.31%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1103, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1085, Accuracy: 286/298 (95.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1066, Accuracy: 286/298 (95.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1191, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1284, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1029, Accuracy: 287/298 (96.31%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1118, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1101, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1028, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0925, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1079, Accuracy: 287/298 (96.31%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0932, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1944, Accuracy: 283/298 (94.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0971, Accuracy: 286/298 (95.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1195, Accuracy: 283/298 (94.97%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1014, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1106, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1279, Accuracy: 284/298 (95.30%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1173, Accuracy: 291/298 (97.65%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0967, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0933, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1289, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0927, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0917, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1112, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1290, Accuracy: 287/298 (96.31%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0878, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0925, Accuracy: 288/298 (96.64%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1269, Accuracy: 287/298 (96.31%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0964, Accuracy: 290/298 (97.32%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1053, Accuracy: 287/298 (96.31%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0917, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1002, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0899, Accuracy: 290/298 (97.32%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0910, Accuracy: 290/298 (97.32%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0869, Accuracy: 291/298 (97.65%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0874, Accuracy: 290/298 (97.32%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1423, Accuracy: 287/298 (96.31%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0979, Accuracy: 287/298 (96.31%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0858, Accuracy: 291/298 (97.65%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1118, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0894, Accuracy: 291/298 (97.65%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0863, Accuracy: 291/298 (97.65%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.1004, Accuracy: 289/298 (96.98%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0934, Accuracy: 292/298 (97.99%)\n",
      "\n",
      "time 0.0 sec:\n",
      "\n",
      "Test set: Average loss: 0.0956, Accuracy: 290/298 (97.32%)\n",
      "\n",
      "CPU times: user 8.56 s, sys: 8.29 s, total: 16.9 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "import time\n",
    "L=[]\n",
    "test_hist=[]\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "for epoch in range(1, 150 + 1):\n",
    "    start=time.time()\n",
    "    loss=train(model, device, train_loader, optimizer, epoch)\n",
    "    L.append(loss)\n",
    "    print(\"time {:.1f} sec:\".format(time.time()-start))\n",
    "    acc=test(model, device, test_loader)\n",
    "    test_hist.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.to(device)\n",
    "\n",
    "y_test=y_test.to(device)\n",
    "\n",
    "pred=model(x_test)\n",
    "pred = pred.max(1, keepdim=True)[1]\n",
    "\n",
    "correct = pred.eq(y_test.view_as(pred)).sum().item()\n",
    "\n",
    "pred=pred.cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[221,   2],\n",
       "       [  6,  69]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred, y_test.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       223\n",
      "           1       0.97      0.92      0.95        75\n",
      "\n",
      "    accuracy                           0.97       298\n",
      "   macro avg       0.97      0.96      0.96       298\n",
      "weighted avg       0.97      0.97      0.97       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(pred, y_test.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452054794520549"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(pred, y_test.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555156950672645"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(pred, y_test.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('./data/feature_8_29.npy')\n",
    "y_test =np.load('/home/yuanshao/EQ_Place/code/data/Y_8_29.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "traindata =TensorDataset(x_train,y_train)\n",
    "testdata = TensorDataset(x_test,y_test)\n",
    "train_loader = DataLoader(traindata,batch_size = 256,shuffle=True)\n",
    "test_loader = DataLoader(testdata,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1859"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1859, 7, 1, 360])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model(x_test)\n",
    "pred = pred.max(1, keepdim=True)[1]\n",
    "correct = pred.eq(y_test.view_as(pred)).sum().item()\n",
    "pred=pred.cpu().numpy().squeeze()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.85px",
    "left": "790px",
    "right": "20px",
    "top": "93px",
    "width": "560px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
