{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import os,obspy,shutil,glob\n",
    "from obspy import read\n",
    "import librosa.display \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "from utils import *\n",
    "from utils.utils import *\n",
    "from utils import data_process, visualize\n",
    "# from utils.models import Att_CNN, CNN, CRNN,M_CRNN\n",
    "# from utils.TFEQ import TFEQ, TFEQ_v1, TFEQ_v2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "###======Settings for different test cases======###\n",
    "SamplingRate = 100 # need to be changed, 25/50/100\n",
    "Duration = 2 # need to be changed, 2/4/10\n",
    "###============###\n",
    "WindowSize = 2 * SamplingRate\n",
    "original_SamplingRate = 100\n",
    "rate = original_SamplingRate/SamplingRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:49<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def pro_data(ex,ey,ez):\n",
    "    X_EQ, Y_EQ, Z_EQ = [], [], []\n",
    "    X_tg, Y_tg, Z_tg =ex,ey,ez\n",
    "\n",
    "    ## 2 sec sliding window with 1 sec overlap\n",
    "    for j in np.arange(0, len(X_tg) - SamplingRate, SamplingRate):\n",
    "        X_batch = X_tg[j:j + WindowSize]\n",
    "        Y_batch = Y_tg[j:j + WindowSize]\n",
    "        Z_batch = Z_tg[j:j + WindowSize]\n",
    "        if len(X_batch) == WindowSize:\n",
    "            X_EQ.append(X_batch)\n",
    "            Y_EQ.append(Y_batch)\n",
    "            Z_EQ.append(Z_batch)\n",
    "\n",
    "    X_EQ, Y_EQ, Z_EQ = np.asarray(X_EQ), np.asarray(Y_EQ), np.asarray(Z_EQ)\n",
    "\n",
    "    X_EQ = X_EQ.reshape(int(len(X_EQ) / (Duration - 1)), Duration - 1, WindowSize, 1)\n",
    "    Y_EQ = Y_EQ.reshape(int(len(Y_EQ) / (Duration - 1)), Duration - 1, WindowSize, 1)\n",
    "    Z_EQ = Z_EQ.reshape(int(len(Z_EQ) / (Duration - 1)), Duration - 1, WindowSize, 1)\n",
    "\n",
    "    X_EQ = X_EQ.reshape(X_EQ.shape[0]*X_EQ.shape[1], X_EQ.shape[2], 1)\n",
    "    Y_EQ = Y_EQ.reshape(Y_EQ.shape[0]*Y_EQ.shape[1], Y_EQ.shape[2], 1)\n",
    "    Z_EQ = Z_EQ.reshape(Z_EQ.shape[0]*Z_EQ.shape[1], Z_EQ.shape[2], 1)\n",
    "\n",
    "    EQ_X = np.dstack((X_EQ, Y_EQ, Z_EQ))\n",
    "    x_train = torch.from_numpy(EQ_X).float()\n",
    "    return x_train\n",
    "\n",
    "filepath='/home/yaso/EQ_Place/dataset/New/20220416/'\n",
    "qry = filepath +'*.mseed'\n",
    "files = glob.glob(qry)\n",
    "files.sort()\n",
    "data, x_train=[],[]\n",
    "for i in tqdm(range(len(files))):\n",
    "    st = read(files[i])\n",
    "\n",
    "    ex, ey, ez = st[0].data, st[1].data, st[2].data\n",
    "\n",
    "    ex  = [x * (2.5 / 2**15) for x in ex]\n",
    "    ey = [x * (2.5 / 2**15) for x in ey] \n",
    "    ez =[x * (2.5 / 2**15) for x in ez]\n",
    "    ex, ey, ez = ex - np.mean(ex), ey - np.mean(ey), ez - np.mean(ez)\n",
    "    data.append([ex,ey,ez])\n",
    "    x_train.append(pro_data(ex,ey,ez))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath='/home/yaso/EQ_Place/dataset/EQ_20210829_130323/'\n",
    "# qry = filepath +'01232972597.csv'\n",
    "# files = glob.glob(qry)\n",
    "# data, x_train=[],[]\n",
    "# for i in tqdm(range(len(files))):\n",
    "#     st = pd.read_csv(files[i])\n",
    "#     st=np.array(st)\n",
    "#     ex, ey, ez = st[:,0], st[:,1], st[:,2]\n",
    "#     ex, ey, ez = ex - np.mean(ex), ey - np.mean(ey), ez - np.mean(ez)\n",
    "#     data.append([ex,ey,ez])\n",
    "#     x_train.append(pro_data(ex,ey,ez))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_com(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Conv_com, self).__init__()\n",
    "        self.conv_1 = nn.Conv1d(\n",
    "            in_channels=1,  out_channels=32, kernel_size=3, stride=2)\n",
    "        self.conv_2 = nn.Conv1d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, stride=2)\n",
    "        self.conv_3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.MaxPool = nn.MaxPool1d(2)\n",
    "        self.rnn = nn.RNN(input_size=736, hidden_size=100)\n",
    "        self.fla = torch.nn.Flatten()\n",
    "        self.fc1 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv_1(x))\n",
    "        out = F.relu(self.conv_2(out))\n",
    "        out = F.relu(self.conv_3(out))\n",
    "        out = self.MaxPool(out)\n",
    "        out = self.fla(out)\n",
    "        out = out.view(-1, 1, out.shape[-1])\n",
    "        out, _ = self.rnn(out)\n",
    "        out = self.fla(out)\n",
    "        return out    \n",
    "\n",
    "class M_CRNN(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(M_CRNN, self).__init__()\n",
    "        self.conv_x = Conv_com()\n",
    "        self.conv_y = Conv_com()\n",
    "        self.conv_z = Conv_com()\n",
    "        self.rnn = nn.RNN(input_size=2208, hidden_size=100)\n",
    "        self.fla = nn.Flatten()\n",
    "        self.dp = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(300, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, y, z = data[:, 0, :], data[:, 1, :], data[:, 2, :]\n",
    "        x = x.view(-1, 1, x.shape[-1])\n",
    "        y = y.view(-1, 1, y.shape[-1])\n",
    "        z = z.view(-1, 1, z.shape[-1])\n",
    "        x_out = self.conv_x(x)\n",
    "        y_out = self.conv_y(y)\n",
    "        z_out = self.conv_z(z)\n",
    "        new_feature = torch.cat([x_out, y_out, z_out], dim=1)\n",
    "#         new_feature = new_feature.view(-1, 1, new_feature.shape[-1])\n",
    "#         out, _ = self.rnn(new_feature)\n",
    "        out = F.relu(self.fc1(new_feature))\n",
    "        out = self.dp(out)\n",
    "#         out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=torch.load('./models/TFEQ_v2.pth')\n",
    "m1.eval()\n",
    "enable_dropout(m1)\n",
    "\n",
    "os.makedirs('./figures/TFEQ_v2/', exist_ok=True)\n",
    "\n",
    "\n",
    "mc_num=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def draw_predict_mc(data, probability, show=False, save_path=None, save=False, lim=0.01,mc_num=10, yline=0.0025):\n",
    "    x_lim = np.arange(0, len(data[0]), 1)\n",
    "    fig, axs = plt.subplots(3, 1, sharex=False, figsize=(6, 5))\n",
    "\n",
    "    axs[0].axhline(y=yline, c=\"green\",  linewidth=0.8)\n",
    "    axs[0].axhline(y=-yline, c=\"green\",  linewidth=0.8)\n",
    "    axs[0].plot(x_lim, data[0], linewidth=0.5)\n",
    "    axs[0].plot(x_lim, data[1], linewidth=0.5)\n",
    "    axs[0].plot(x_lim, data[2], linewidth=0.5)\n",
    "    axs[0].set_ylim((-lim, lim))\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    x_lim = np.arange(0, len(probability[0]), 1)\n",
    "    for m in range(mc_num):\n",
    "        axs[1].plot(x_lim, probability[m], linewidth=0.5)\n",
    "    axs[1].set_ylim((0, 1))\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    axs[2].plot(x_lim, probability.mean(axis=0), linewidth=0.8)\n",
    "    axs[2].set_ylim((0, 1))\n",
    "    axs[2].grid(True)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(save_path, dpi=100)\n",
    "    if not show:\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [01:04<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(25, len(files))):\n",
    "    d1=x_train[i][:300].cuda()\n",
    "    d2=x_train[i][300:400].cuda()\n",
    "    d3=x_train[i][400:].cuda()\n",
    "    probability=[]\n",
    "    for m in range(mc_num):\n",
    "        output = m1(d1)\n",
    "        output = F.softmax(output, dim=1)[:,1]\n",
    "        p1=output.squeeze().cpu().detach().numpy()\n",
    "\n",
    "        output = m1(d2)\n",
    "        output = F.softmax(output, dim=1)[:,1]\n",
    "        p2=output.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        output = m1(d3)\n",
    "        output = F.softmax(output, dim=1)[:,1]\n",
    "        p3=output.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        p=np.hstack([p1,p2,p3])\n",
    "        probability.append(p)\n",
    "    probability=np.vstack(probability)\n",
    "    draw_predict_mc(data[i], probability, show=False,save=True,mc_num=10,save_path='figures/TFEQ_v2/'+files[i][-17:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=torch.load('./models/TFEQ.pth')\n",
    "m1.eval()\n",
    "enable_dropout(m1)\n",
    "m2=torch.load('./models/CRNN.pth')\n",
    "m2.eval()\n",
    "enable_dropout(m2)\n",
    "m3=torch.load('./models/M_CRNN.pth')\n",
    "m3.eval()\n",
    "enable_dropout(m3)\n",
    "\n",
    "os.makedirs('./figures/TFEQ/', exist_ok=True)\n",
    "os.makedirs('./figures/CRNN/', exist_ok=True)\n",
    "os.makedirs('./figures/M_CRNN/', exist_ok=True)\n",
    "\n",
    "mc_num=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def draw_predict_mc(data, probability, show=False, save_path=None, save=False, lim=0.01,mc_num=10, yline=0.0025):\n",
    "    x_lim = np.arange(0, len(data[0]), 1)\n",
    "    fig, axs = plt.subplots(3, 1, sharex=False, figsize=(6, 5))\n",
    "\n",
    "    axs[0].axhline(y=yline, c=\"green\",  linewidth=0.8)\n",
    "    axs[0].axhline(y=-yline, c=\"green\",  linewidth=0.8)\n",
    "    axs[0].plot(x_lim, data[0], linewidth=0.5)\n",
    "    axs[0].plot(x_lim, data[1], linewidth=0.5)\n",
    "    axs[0].plot(x_lim, data[2], linewidth=0.5)\n",
    "    axs[0].set_ylim((-lim, lim))\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    x_lim = np.arange(0, len(probability[0]), 1)\n",
    "    for m in range(mc_num):\n",
    "        axs[1].plot(x_lim, probability[m], linewidth=0.5)\n",
    "    axs[1].set_ylim((0, 1))\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    axs[2].plot(x_lim, probability.mean(axis=0), linewidth=0.8)\n",
    "    axs[2].set_ylim((0, 1))\n",
    "    axs[2].grid(True)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(save_path, dpi=100)\n",
    "    if not show:\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [01:16<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(files))):\n",
    "    d1=x_train[i][:300].cuda()\n",
    "    d2=x_train[i][300:600].cuda()\n",
    "    d3=x_train[i][600:].cuda()\n",
    "    probability=[]\n",
    "    for m in range(mc_num):\n",
    "        output = m1(d1)\n",
    "        output = F.softmax(output, dim=1)[:,1]\n",
    "        p1=output.squeeze().cpu().detach().numpy()\n",
    "\n",
    "        output = m1(d2)\n",
    "        output = F.softmax(output, dim=1)[:,1]\n",
    "        p2=output.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        output = m1(d3)\n",
    "        output = F.softmax(output, dim=1)[:,1]\n",
    "        p3=output.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        p=np.hstack([p1,p2,p3])\n",
    "        probability.append(p)\n",
    "    probability=np.vstack(probability)\n",
    "    draw_predict_mc(data[i], probability, show=False,save=True,mc_num=10,save_path='figures/TFEQ/'+files[i][-17:-6])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(files))):\n",
    "    d=x_train[i].reshape(-1, 3, 200).cuda()\n",
    "    probability=[]\n",
    "    for m in range(mc_num):\n",
    "        output = m3(d)\n",
    "        output = F.softmax(output, dim=1)[:,1]\n",
    "        p=output.squeeze().cpu().detach().numpy()\n",
    "        probability.append(p)\n",
    "    probability=np.vstack(probability)\n",
    "#     draw_predict(data[i], probability, show=True)\n",
    "    draw_predict_mc(data[i], probability, show=False,save=True,save_path='figures/M_CRNN/'+files[i][-17:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# no-Mc dropout\n",
    "for i in tqdm(range(len(files))):\n",
    "    d=x_train[i][:420].cuda()\n",
    "    output = m1(d)\n",
    "    output = F.softmax(output, dim=1)[:,1]\n",
    "    probability=output.squeeze().cpu().detach().numpy()\n",
    "    d=x_train[i][420:].cuda()\n",
    "    output = m1(d)\n",
    "    output = F.softmax(output, dim=1)[:,1]\n",
    "    probability1=output.squeeze().cpu().detach().numpy()\n",
    "\n",
    "    probability=np.hstack([probability,probability1])\n",
    "    draw_predict(data[i], probability, show=False,save=True,save_path='figures/TFEQ/'+files[i][-17:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# no-Mc dropout\n",
    "for i in tqdm(range(len(files))):\n",
    "    d=x_train[i].reshape(-1, 3, 200).cuda()\n",
    "    output = m2(d)\n",
    "    output = F.softmax(output, dim=1)[:,1]\n",
    "    probability=output.squeeze().cpu().detach().numpy()\n",
    "#     draw_predict(data[i], probability, show=True)\n",
    "    draw_predict(data[i], probability, show=False,save=True,save_path='figures/CRNN/'+files[i][-17:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# no-Mc dropout\n",
    "for i in tqdm(range(len(files))):\n",
    "    d=x_train[i].reshape(-1, 3, 200).cuda()\n",
    "    output = m3(d)\n",
    "    output = F.softmax(output, dim=1)[:,1]\n",
    "    probability=output.squeeze().cpu().detach().numpy()\n",
    "#     draw_predict(data[i], probability, show=True)\n",
    "    draw_predict(data[i], probability, show=False,save=True,save_path='figures/M_CRNN/'+files[i][-17:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=3,  out_channels=64, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=64,  out_channels=64, kernel_size=3, stride=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fla = nn.Flatten()\n",
    "        self.dp = nn.Dropout(p=0.1)\n",
    "        self.rnn = nn.RNN(input_size=3072, hidden_size=100)\n",
    "        self.fc1 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.conv1(data))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.dp(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.fla(out)\n",
    "        out = out.view(-1, 1, out.shape[-1])\n",
    "        out, _ = self.rnn(out)\n",
    "        out = self.fla(out)\n",
    "        out = self.fc1(out)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "m2=torch.load('./models/CRNN_d1.pth')\n",
    "m2.eval()\n",
    "enable_dropout(m2)\n",
    "\n",
    "os.makedirs('./figures/CRNN_d1/', exist_ok=True)\n",
    "mc_num=10\n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "    d=x_train[i].reshape(-1, 3, 200).cuda()\n",
    "    probability=[]\n",
    "    for m in range(mc_num):\n",
    "        output = m2(d)\n",
    "        output = F.softmax(output, dim=1)[:,1]\n",
    "        p=output.squeeze().cpu().detach().numpy()\n",
    "        probability.append(p)\n",
    "    probability=np.vstack(probability)\n",
    "#     draw_predict(data[i], probability, show=True)\n",
    "    draw_predict_mc(data[i], probability, show=False,save=True,save_path='figures/CRNN_d1/'+files[i][-17:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01232972140, 01232972597, 01232971750, 01232973198\n",
    "\n",
    "01232973617  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
