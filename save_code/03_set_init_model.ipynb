{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=100\n",
    "def extrtact_features(mse, Pxx_den):\n",
    "    # 均值 方差\n",
    "    f_m=np.mean(Pxx_den)\n",
    "    f_std= np.std(Pxx_den)\n",
    "    # 四分位距number of outlier\n",
    "    Q1 = np.percentile(Pxx_den, 25)\n",
    "    Q3 = np.percentile(Pxx_den, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    num_outlier = sum((Pxx_den < (Q1 - 1.5 * IQR)) | (Pxx_den > (Q3 + 1.5 * IQR)))\n",
    "    #MSE\n",
    "    f_mse=sum(np.square(Pxx_den-np.mean(Pxx_den)))/len(Pxx_den)\n",
    "    \n",
    "    p_mse = sum(np.square(Pxx_den - np.mean(Pxx_den))) / len(Pxx_den)\n",
    "    \n",
    "    #Max diff\n",
    "    f_md=np.max(Pxx_den)-np.min(Pxx_den)\n",
    "    return mse,f_m,f_std,IQR,num_outlier,p_mse,f_mse,f_md\n",
    "\n",
    "def all_features(ex,ey,ez):\n",
    "    ex_mse = sum(np.square(ex - np.mean(ex))) / len(ex)\n",
    "    ey_mse = sum(np.square(ey - np.mean(ey))) / len(ey)\n",
    "    ez_mse = sum(np.square(ez - np.mean(ez))) / len(ez)\n",
    "    ex,ey,ez=ex-np.mean(ex), ey-np.mean(ey), ez-np.mean(ez)\n",
    "    sos = signal.butter(2, 35, 'lowpass',fs=100,output='sos')\n",
    "    ex = signal.sosfilt(sos, ex)\n",
    "    ey = signal.sosfilt(sos, ey)\n",
    "    ez = signal.sosfilt(sos, ez)\n",
    "    #calculate PSD\n",
    "    fre, Pxx_den = signal.periodogram(ex, fs)\n",
    "    Pxx_den=10*np.log10(abs(Pxx_den))[1:]\n",
    "    fre, Pyy_den = signal.periodogram(ey, fs)\n",
    "    Pyy_den=10*np.log10(abs(Pyy_den))[1:]\n",
    "    fre, Pzz_den = signal.periodogram(ez, fs)\n",
    "    Pzz_den=10*np.log10(abs(Pzz_den))[1:]\n",
    "    fx=extrtact_features(ex_mse, Pxx_den)\n",
    "    fy=extrtact_features(ey_mse, Pyy_den)\n",
    "    fz=extrtact_features(ez_mse, Pzz_den)\n",
    "    return [fx,fy,fz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初步分好的数据，选择文件数量较少的两天\n",
    "# 读取分好的文件路径\n",
    "path='C:\\xxx\\dataset\\init_label\\\\'\n",
    "True_path, False_path=[], []\n",
    "# folder_210=os.listdir(path+'2_10\\\\')\n",
    "o_path='C:\\xxx\\dataset\\EQ_20220210_172034\\\\'\n",
    "for f in os.listdir(path+'2_10\\True\\\\'):xxx\n",
    "    True_path.append(o_path+f[:-4]+'.csv')\n",
    "for f in os.listdir(path+'2_10\\False\\\\'):\n",
    "    False_path.append(o_path+f[:-4]+'.csv')\n",
    "\n",
    "o_path='C:\\xxx\\dataset\\EQ_90s_02and03_15\\EQ_90s_02_15\\\\'\n",
    "for f in os.listdir(path+'2_15\\True\\\\'):\n",
    "    True_path.append(o_path+f[:-4]+'.csv')\n",
    "for f in os.listdir(path+'2_15\\False\\\\'):\n",
    "    False_path.append(o_path+f[:-4]+'.csv')\n",
    "\n",
    "o_path='C:\\xxx\\dataset\\EQ_90s_02and03_15\\EQ_90s_03_15\\\\'\n",
    "for f in os.listdir(path+'3_15\\True\\\\'):\n",
    "    True_path.append(o_path+f[:-4]+'.csv')\n",
    "for f in os.listdir(path+'3_15\\False\\\\'):\n",
    "    False_path.append(o_path+f[:-4]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据分好的文件路径读取数据，获取初步特征，并设置初步标签\n",
    "X, Y=[], []\n",
    "for f in True_path:\n",
    "    df=pd.read_csv(f)\n",
    "    df=np.array(df)[:,:3]\n",
    "    ex,ey,ez=df[:,0],df[:,1],df[:,2]\n",
    "    X.append(all_features(ex,ey,ez))\n",
    "    Y.append(1)\n",
    "for f in False_path:\n",
    "    df=pd.read_csv(f)\n",
    "    df=np.array(df)[:,:3]\n",
    "    ex,ey,ez=df[:,0],df[:,1],df[:,2]\n",
    "    X.append(all_features(ex,ey,ez))\n",
    "    Y.append(0)\n",
    "X=np.array(X)\n",
    "X=X.reshape(X.shape[0],-1)\n",
    "Y=np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    652\n",
       "1    216\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score 正则化\n",
    "ss = StandardScaler()\n",
    "z_X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用初步划分的训练集训练一个机器学习模型\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size = 0.3,random_state = 42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf.fit(x_train, y_train)\n",
    "label=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  33]\n",
      " [ 24  28]]\n",
      "0.7816091954022989\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label, y_test))\n",
    "print(accuracy_score(label, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "from joblib import dump, load\n",
    "dump(clf, './models/rf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  33]\n",
      " [ 24  28]]\n",
      "0.7816091954022989\n"
     ]
    }
   ],
   "source": [
    "#读取模型并测试\n",
    "rf=load('./models/rf.model')\n",
    "label=rf.predict(x_test)\n",
    "print(confusion_matrix(label, y_test))\n",
    "print(accuracy_score(label, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183  44]\n",
      " [ 17  17]]\n",
      "0.7662835249042146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "label=clf.predict(x_test)\n",
    "print(confusion_matrix(label, y_test))\n",
    "print(accuracy_score(label, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175  29]\n",
      " [ 25  32]]\n",
      "0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=200)\n",
    "clf.fit(x_train, y_train)\n",
    "label=clf.predict(x_test)\n",
    "print(confusion_matrix(label, y_test))\n",
    "print(accuracy_score(label, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175  29]\n",
      " [ 25  32]]\n",
      "0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "dump(clf, './models/gboost.model')\n",
    "gboost=load('./models/gboost.model')\n",
    "label=gboost.predict(x_test)\n",
    "print(confusion_matrix(label, y_test))\n",
    "print(accuracy_score(label, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
