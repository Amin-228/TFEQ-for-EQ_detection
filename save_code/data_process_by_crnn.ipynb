{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os,time,pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import dump, load\n",
    "# from utils import data_process, visualize\n",
    "# from utils.utils import train, test, summary, setup_seed\n",
    "# from utils.models import Att_CNN, CNN, TFEQ\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    370\n",
      "1     44\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "data,label=[],[]\n",
    "data.append(np.load('/home/yaso/EQ_Place/code/data/X_3_15.npy', allow_pickle=True))\n",
    "label.append(np.load('/home/yaso/EQ_Place/code/data/Y_3_15.npy'))\n",
    "\n",
    "data=np.vstack(data)\n",
    "label=np.hstack(label)\n",
    "print(pd.value_counts(label))\n",
    "num=pd.value_counts(label)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###======Settings for different test cases======###\n",
    "SamplingRate = 100 # need to be changed, 25/50/100\n",
    "Duration = 2 # need to be changed, 2/4/10\n",
    "###============###\n",
    "WindowSize = 2 * SamplingRate\n",
    "original_SamplingRate = 100\n",
    "rate = original_SamplingRate/SamplingRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 13310.45it/s]\n",
      "100%|██████████| 370/370 [00:00<00:00, 5149.99it/s]\n"
     ]
    }
   ],
   "source": [
    "X_EQ, Y_EQ, Z_EQ = [], [], []\n",
    "for i in tqdm(range(num)):\n",
    "    X = data[i][0]\n",
    "    X_peak = np.where(X == np.max(X))[0][0]\n",
    "    start = X_peak - int(SamplingRate)\n",
    "    end = X_peak + int(SamplingRate) * (Duration - 1)\n",
    "    X_tg, Y_tg, Z_tg = data[i][0][start:end], data[i][1][start:end], data[i][\n",
    "        2][start:end]\n",
    "    X_tg = (X_tg - np.mean(X_tg))\n",
    "    Y_tg = (Y_tg - np.mean(Y_tg)) \n",
    "    Z_tg = (Z_tg - np.mean(Z_tg)) \n",
    "    if len(X_tg) == SamplingRate * Duration:\n",
    "        ## 2 sec sliding window with 1 sec overlap\n",
    "        for j in np.arange(0, len(X_tg) - SamplingRate, SamplingRate):\n",
    "            X_batch = X_tg[j:j + WindowSize]\n",
    "            Y_batch = Y_tg[j:j + WindowSize]\n",
    "            Z_batch = Z_tg[j:j + WindowSize]\n",
    "            if len(X_batch) == WindowSize:\n",
    "                X_EQ.append(X_batch)\n",
    "                Y_EQ.append(Y_batch)\n",
    "                Z_EQ.append(Z_batch)\n",
    "\n",
    "X_EQ, Y_EQ, Z_EQ = np.asarray(X_EQ), np.asarray(Y_EQ), np.asarray(Z_EQ)\n",
    "\n",
    "X_EQ = X_EQ.reshape(int(len(X_EQ) / (Duration - 1)), Duration - 1, WindowSize, 1)\n",
    "Y_EQ = Y_EQ.reshape(int(len(Y_EQ) / (Duration - 1)), Duration - 1, WindowSize, 1)\n",
    "Z_EQ = Z_EQ.reshape(int(len(Z_EQ) / (Duration - 1)), Duration - 1, WindowSize, 1)\n",
    "\n",
    "X_HA, Y_HA, Z_HA = [], [], []\n",
    "for i in tqdm(range(num, len(data))):\n",
    "    X, Y, Z = data[i][0], data[i][1], data[i][2]\n",
    "#     X_tg = (X - np.mean(X)) / 9.80665\n",
    "#     Y_tg = (Y - np.mean(Y)) / 9.80665\n",
    "#     Z_tg = (Z - np.mean(Z)) / 9.80665\n",
    "    X_tg = (X - np.mean(X))\n",
    "    Y_tg = (Y - np.mean(Y))\n",
    "    Z_tg = (Z - np.mean(Z))\n",
    "    for j in np.arange(0, 400 - SamplingRate, SamplingRate):\n",
    "        X_batch = X_tg[j:j + WindowSize]\n",
    "        Y_batch = Y_tg[j:j + WindowSize]\n",
    "        Z_batch = Z_tg[j:j + WindowSize]\n",
    "        if len(X_batch) == WindowSize:\n",
    "            X_HA.append(X_batch)\n",
    "            Y_HA.append(Y_batch)\n",
    "            Z_HA.append(Z_batch)\n",
    "\n",
    "X_HA, Y_HA, Z_HA = np.asarray(X_HA), np.asarray(Y_HA), np.asarray(Z_HA)\n",
    "\n",
    "X_HA = X_HA.reshape(X_HA.shape[0], X_HA.shape[1], 1)\n",
    "Y_HA = Y_HA.reshape(Y_HA.shape[0], Y_HA.shape[1], 1)\n",
    "Z_HA = Z_HA.reshape(Z_HA.shape[0], Z_HA.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(X_EQ))\n",
    "X_EQ_train, X_EQ_test, train_index, test_index = train_test_split(X_EQ, indices, test_size=0.2, random_state=42)\n",
    "Y_EQ_train, Y_EQ_test = Y_EQ[train_index], Y_EQ[test_index]\n",
    "Z_EQ_train, Z_EQ_test = Z_EQ[train_index], Z_EQ[test_index]\n",
    "\n",
    "X_EQ_train = X_EQ_train.reshape(X_EQ_train.shape[0]*X_EQ_train.shape[1], X_EQ_train.shape[2], 1)\n",
    "Y_EQ_train = Y_EQ_train.reshape(Y_EQ_train.shape[0]*Y_EQ_train.shape[1], Y_EQ_train.shape[2], 1)\n",
    "Z_EQ_train = Z_EQ_train.reshape(Z_EQ_train.shape[0]*Z_EQ_train.shape[1], Z_EQ_train.shape[2], 1)\n",
    "\n",
    "X_EQ_test = X_EQ_test.reshape(X_EQ_test.shape[0]*X_EQ_test.shape[1], X_EQ_test.shape[2], 1)\n",
    "Y_EQ_test = Y_EQ_test.reshape(Y_EQ_test.shape[0]*Y_EQ_test.shape[1], Y_EQ_test.shape[2], 1)\n",
    "Z_EQ_test = Z_EQ_test.reshape(Z_EQ_test.shape[0]*Z_EQ_test.shape[1], Z_EQ_test.shape[2], 1)\n",
    "\n",
    "indices2 = np.arange(len(X_HA))\n",
    "X_HA_train, X_HA_test, train_index2, test_index2 = train_test_split(X_HA, indices2, test_size=0.2, random_state=42)\n",
    "Y_HA_train, Y_HA_test = Y_HA[train_index2], Y_HA[test_index2]\n",
    "Z_HA_train, Z_HA_test = Z_HA[train_index2], Z_HA[test_index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_X_train = np.dstack((X_EQ_train, Y_EQ_train, Z_EQ_train))\n",
    "HA_X_train = np.dstack((X_HA_train, Y_HA_train, Z_HA_train))\n",
    "EQ_y_train = np.ones(len(X_EQ_train))\n",
    "HA_y_train = np.zeros(len(X_HA_train))\n",
    "X_train = np.vstack((EQ_X_train, HA_X_train))\n",
    "y_train = np.hstack((EQ_y_train, HA_y_train)).reshape(-1,1)\n",
    "\n",
    "dic1={'x_train':X_train,'y_train':y_train}\n",
    "np.save(\"data_train_1.npy\",dic1)\n",
    "\n",
    "EQ_X_test = np.dstack((X_EQ_test, Y_EQ_test, Z_EQ_test))\n",
    "HA_X_test = np.dstack((X_HA_test, Y_HA_test, Z_HA_test))\n",
    "EQ_y_test = np.ones(len(X_EQ_test))\n",
    "HA_y_test = np.zeros(len(X_HA_test))\n",
    "X_test = np.vstack((EQ_X_test, HA_X_test))\n",
    "y_test = np.hstack((EQ_y_test, HA_y_test)).reshape(-1,1)\n",
    "\n",
    "dic2={'x_test':X_test,'y_test':y_test}\n",
    "np.save(\"data_test_1.npy\",dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./data_train_1.npy\", allow_pickle=True)\n",
    "x_train1 = data.item().get(\"x_train\")\n",
    "y_train1 = data.item().get(\"y_train\")\n",
    "data = np.load(\"./data_train_2.npy\", allow_pickle=True)\n",
    "x_train2 = data.item().get(\"x_train\")\n",
    "y_train2 = data.item().get(\"y_train\")\n",
    "data = np.load(\"./data_train_3.npy\", allow_pickle=True)\n",
    "x_train3 = data.item().get(\"x_train\")\n",
    "y_train3 = data.item().get(\"y_train\")\n",
    "data = np.load(\"./data_train_4.npy\", allow_pickle=True)\n",
    "x_train4 = data.item().get(\"x_train\")\n",
    "y_train4 = data.item().get(\"y_train\")\n",
    "data = np.load(\"./data_train_5.npy\", allow_pickle=True)\n",
    "x_train5 = data.item().get(\"x_train\")\n",
    "y_train5 = data.item().get(\"y_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./data_test_1.npy\", allow_pickle=True)\n",
    "x_test1 = data.item().get(\"x_test\")\n",
    "y_test1 = data.item().get(\"y_test\")\n",
    "data = np.load(\"./data_test_2.npy\", allow_pickle=True)\n",
    "x_test2 = data.item().get(\"x_test\")\n",
    "y_test2 = data.item().get(\"y_test\")\n",
    "data = np.load(\"./data_test_3.npy\", allow_pickle=True)\n",
    "x_test3 = data.item().get(\"x_test\")\n",
    "y_test3 = data.item().get(\"y_test\")\n",
    "data = np.load(\"./data_test_4.npy\", allow_pickle=True)\n",
    "x_test4 = data.item().get(\"x_test\")\n",
    "y_test4 = data.item().get(\"y_test\")\n",
    "data = np.load(\"./data_test_5.npy\", allow_pickle=True)\n",
    "x_test5 = data.item().get(\"x_test\")\n",
    "y_test5 = data.item().get(\"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.vstack([y_train1,y_train2,y_train3,y_train4,y_train5])\n",
    "y_test = np.vstack([y_test1,y_test2,y_test3,y_test4,y_test5])\n",
    "\n",
    "x_train = np.vstack([x_train1,x_train2,x_train3,x_train4,x_train5])\n",
    "x_test = np.vstack([x_test1,x_test2,x_test3,x_test4,x_test5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1={'x_train':x_train,'y_train':y_train}\n",
    "np.save(\"data_train.npy\",dic1)\n",
    "dic2={'x_test':x_test,'y_test':y_test}\n",
    "np.save(\"data_test.npy\",dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4714, 200, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 477.844,
   "position": {
    "height": "40px",
    "left": "1119px",
    "right": "20px",
    "top": "60px",
    "width": "560px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
